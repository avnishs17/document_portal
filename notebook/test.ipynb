{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990f60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab266a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e96af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"moonshotai/kimi-k2-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5264c6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 32, 'total_tokens': 40, 'completion_time': 0.013631701, 'prompt_time': 0.001045352, 'queue_time': 0.296447259, 'total_time': 0.014677053}, 'model_name': 'moonshotai/kimi-k2-instruct', 'system_fingerprint': 'fp_c5bd0a648b', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--cb966ba7-e7fa-4b52-889e-230d70e4b262-0', usage_metadata={'input_tokens': 32, 'output_tokens': 8, 'total_tokens': 40})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8917abdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ef2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d832bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=embeddings.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e857fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ace2c3",
   "metadata": {},
   "source": [
    "1.  Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7373c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695a8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea59b1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084285be",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), \"data\", \"graphmae.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6612d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "984e7ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5943cc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed7c9690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GraphMAE2: A Decoding-Enhanced Masked Self-Supervised\\nGraph Learner\\nZhenyu Hou\\nTsinghua University, China\\nhouzy21@mails.tsinghua.edu.cn\\nYufei He∗\\nBeijing Institute of Technology, China\\nyufei.he@bit.edu.cn\\nYukuo Cen\\nTsinghua University, China\\ncyk20@mails.tsinghua.edu.cn\\nXiao Liu\\nTsinghua University, China\\nliuxiao21@mails.tsinghua.edu.cn\\nYuxiao Dong†\\nTsinghua University, China\\nyuxiaod@tsinghua.edu.cn\\nEvgeny Kharlamov\\nBosch Center for Artificial\\nIntelligence, Germany\\nevgeny.kharlamov@de.bosch.com\\nJie Tang†\\nTsinghua University, China\\njietang@tsinghua.edu.cn\\nABSTRACT\\nGraph self-supervised learning (SSL), including contrastive and\\ngenerative approaches, offers great potential to address the funda-\\nmental challenge of label scarcity in real-world graph data. Among\\nboth sets of graph SSL techniques, the masked graph autoencoders\\n(e.g., GraphMAE)—one type of generative methods—have recently\\nproduced promising results. The idea behind this is to reconstruct\\nthe node features (or structures)—that'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "224601f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, \n",
    "    chunk_overlap=250,\n",
    "    length_function=len\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "565d85ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25a4f0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e47381d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       " 'creator': 'LaTeX with acmart 2022/04/09 v1.84 Typesetting articles for the Association for Computing Machinery and hyperref 2020-05-15 v7.00e Hypertext links for LaTeX',\n",
       " 'creationdate': '2023-04-12T00:29:18+00:00',\n",
       " 'moddate': '2023-04-12T00:29:18+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2',\n",
       " 'subject': '-  Computing methodologies  ->  Learning latent representations.-  Information systems  ->  Data mining.',\n",
       " 'title': 'GraphMAE2: A Decoding-Enhanced Masked Self-Supervised Graph Learner',\n",
       " 'trapped': '/False',\n",
       " 'source': 'b:\\\\LLOPS\\\\document_portal\\\\notebook\\\\data\\\\graphmae.pdf',\n",
       " 'total_pages': 10,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bf454fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GraphMAE2: A Decoding-Enhanced Masked Self-Supervised\\nGraph Learner\\nZhenyu Hou\\nTsinghua University, China\\nhouzy21@mails.tsinghua.edu.cn\\nYufei He∗\\nBeijing Institute of Technology, China\\nyufei.he@bit.edu.cn\\nYukuo Cen\\nTsinghua University, China\\ncyk20@mails.tsinghua.edu.cn\\nXiao Liu\\nTsinghua University, China\\nliuxiao21@mails.tsinghua.edu.cn\\nYuxiao Dong†\\nTsinghua University, China\\nyuxiaod@tsinghua.edu.cn\\nEvgeny Kharlamov\\nBosch Center for Artificial\\nIntelligence, Germany\\nevgeny.kharlamov@de.bosch.com\\nJie Tang†\\nTsinghua University, China\\njietang@tsinghua.edu.cn\\nABSTRACT\\nGraph self-supervised learning (SSL), including contrastive and\\ngenerative approaches, offers great potential to address the funda-\\nmental challenge of label scarcity in real-world graph data. Among\\nboth sets of graph SSL techniques, the masked graph autoencoders\\n(e.g., GraphMAE)—one type of generative methods—have recently\\nproduced promising results. The idea behind this is to reconstruct'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b95f8e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'both sets of graph SSL techniques, the masked graph autoencoders\\n(e.g., GraphMAE)—one type of generative methods—have recently\\nproduced promising results. The idea behind this is to reconstruct\\nthe node features (or structures)—that are randomly masked from\\nthe input—with the autoencoder architecture. However, the per-\\nformance of masked feature reconstruction naturally relies on the\\ndiscriminability of the input features and is usually vulnerable to\\ndisturbance in the features. In this paper, we present a masked\\nself-supervised learning framework1 GraphMAE2 with the goal\\nof overcoming this issue. The idea is to impose regularization on\\nfeature reconstruction for graph SSL. Specifically, we design the\\nstrategies of multi-view random re-mask decoding and latent rep-\\nresentation prediction to regularize the feature reconstruction. The\\nmulti-view random re-mask decoding is to introduce randomness\\ninto reconstruction in the feature space, while the latent represen-'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea59a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbf1aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a036771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vector = embeddings.embed_documents([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19e30a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 768)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_vector), len(doc_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f6f5fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e636dee",
   "metadata": {},
   "source": [
    "Token → Word\n",
    "\n",
    "A chunk is a group of tokens (words/characters) used for indexing and retrieval.\n",
    "\n",
    "1. Vector stores in RAG can be categorized by storage type:\n",
    "\n",
    "1. In-memory: Fast, stored in RAM (e.g., FAISS, Chroma)\n",
    "\n",
    "2. On-disk: Persisted locally (e.g., FAISS with persistence, Chroma)\n",
    "\n",
    "3. Cloud-based: Scalable, managed solutions (e.g., Pinecone, Weaviate, Milvus, MongoDB Atlas Vector Search, AstraDB)\n",
    "\n",
    "Note: FAISS has no official cloud-native variant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e49ef8",
   "metadata": {},
   "source": [
    "2. Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5eeb0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = vector_store.similarity_search(\"What is graph masked autoencoder?\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fdb8875c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Denoting the hidden embedding 𝑯 ∈R𝑁×𝑑, the general goal of\\ngraph autoencoders is to learn representation𝑯 or a well-initialized\\n𝑓𝐸 through reconstructing input node features or structure:\\n𝑯 = 𝑓𝐸(𝑨,𝑿), eG= 𝑓𝐷(𝑨,𝑯) (1)\\nwhere eGdenotes the reconstructed graph characteristics, which\\ncan be structure, node features or both.\\nOverview of masked feature reconstruction. The idea of masked\\nautoencoder has seen successful practice in graph SSL [18]. As a\\nform of more general denoising autoencoders, it removes a portion\\nof data in the graph, e.g., node features or links, with the masking\\noperation and learns to predict the masked content. And it has\\nbeen demonstrated that reconstructing masked node features as',\n",
       " 'target generator are discarded, and only the GNN encoder is used\\nto generating embeddings or finetuned for downstream tasks.\\nExtending to large-scale graph Extending self-supervised learn-\\ning to large-scale graphs is of great practical significance, yet few\\nefforts have been devoted to this scenario. Existing graph SSL works')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs[0].page_content, relevant_docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d5afb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vector_store.similarity_search(\"maksed autoencoder\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ae3967c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the code. The sources of the codes used are as follows:\n",
      "•BRGL: https://github.com/Namkyeong/BGRL_Pytorch\n",
      "•GRACE: https://github.com/CRIPAC-DIG/GRACE\n",
      "•CCA-SSG: https://github.com/hengruizhang98/CCA-SSG/\n",
      "•GraphMAE:https://github.com/THUDM/GraphMAE\n"
     ]
    }
   ],
   "source": [
    "for doc in relevant_doc:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fc8706",
   "metadata": {},
   "source": [
    "## Keyword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40cc7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 2\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a4a78076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Denoting the hidden embedding 𝑯 ∈R𝑁×𝑑, the general goal of\\ngraph autoencoders is to learn representation𝑯 or a well-initialized\\n𝑓𝐸 through reconstructing input node features or structure:\\n𝑯 = 𝑓𝐸(𝑨,𝑿), eG= 𝑓𝐷(𝑨,𝑯) (1)\\nwhere eGdenotes the reconstructed graph characteristics, which\\ncan be structure, node features or both.\\nOverview of masked feature reconstruction. The idea of masked\\nautoencoder has seen successful practice in graph SSL [18]. As a\\nform of more general denoising autoencoders, it removes a portion\\nof data in the graph, e.g., node features or links, with the masking\\noperation and learns to predict the masked content. And it has\\nbeen demonstrated that reconstructing masked node features as'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = retriever.invoke(\"What is graph masked autoencoder?\")\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e52b00b",
   "metadata": {},
   "source": [
    "## Context based retrieval from vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a0996ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "                  Answer the question based on the context provided below.\n",
    "                  If the context does not contain enough information to answer the question,\n",
    "                say \"I don't have enough information about this\".\n",
    "\n",
    "                Context: {context}\n",
    "                Question: {question}\n",
    "\n",
    "                Answer:\n",
    "                \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44101887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "572b7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c7a7d76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n                  Answer the question based on the context provided below.\\n                  If the context does not contain enough information to answer the question,\\n                say \"I don\\'t have enough information about this\".\\n\\n                Context: {context}\\n                Question: {question}\\n\\n                Answer:\\n                ')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c604e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "17f5a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da4ac693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_output(docs):\n",
    "\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0b791913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bac71887",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_output, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c4f45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A graph masked autoencoder is a type of graph autoencoder that follows the masked-autoencoder paradigm used in self-supervised learning. It randomly masks (removes) a portion of the graph’s data—such as node features or links—then trains an encoder–decoder pair to reconstruct the masked content. After pre-training, the decoder is discarded and only the GNN encoder is retained to produce node embeddings or to be fine-tuned for downstream tasks.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is graph masked autoencoder?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "09f9dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the trending graph representational learning methods are centered around **self-supervised learning (SSL)** approaches for graph data, particularly **graph contrastive learning (GCL)**. Key developments include:\\n\\n1. **SimGRACE** [47]: A framework that enables graph contrastive learning **without data augmentation**, simplifying the process while maintaining effectiveness.  \\n2. **InfoGCL** [48]: Focuses on **information-aware contrastive learning**, incorporating mutual information maximization for better graph representations.  \\n3. **GraphCL** [51]: Introduces **augmentation-based contrastive learning**, leveraging transformations like node/feature perturbations to create positive/negative pairs for training.  \\n\\nThese methods aim to learn robust node/graph embeddings **without labeled data**, with applications in large-scale graphs. However, the context highlights that **scaling SSL to large graphs remains underexplored**.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Can you tell me about treding graph representational learning methods?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091a6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "document_portal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
